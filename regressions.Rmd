---
title: "regressions"
author: "Katherine Siegel"
date: "February 10, 2020"
output: html_document
---

## Description
Get set of random forested points (2008) and run logistic regression on factors contributing to likelihood of transitioning to another land cover in 2018.

## Set up
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

### Open packages
library(tidyverse)
library(sf)
library(raster)
library(lmtest)

### Function to sample non-NA cells
### r: raster, n: number of points
### source: https://gis.stackexchange.com/questions/207119/sampling-random-points-from-large-raster-file-with-replacement-using-r
fastRandomPoints <- function(r, n) {
  if(raster::nlayers(r) > 1) r <- r[[1]]
  v <- raster::getValues(r)
  v.notNA <- which(!is.na(v))
  x <- sample(v.notNA, n)
  pts <- raster::xyFromCell(r, x)
  return(pts)
}

#### Function to check correlation
cor.prob <- function (X, dfr = nrow(X) - 2) {
  R <- cor(X, use="pairwise.complete.obs")
  above <- row(R) < col(R)
  r2 <- R[above]^2
  Fstat <- r2 * dfr/(1 - r2)
  R[above] <- 1 - pf(Fstat, 1, dfr)
  R[row(R) == col(R)] <- NA
  R
}
flattenSquareMatrix <- function(m) {
  if( (class(m) != "matrix") | (nrow(m) != ncol(m))) stop("Must be a square matrix.") 
  if(!identical(rownames(m), colnames(m))) stop("Row and column names must be equal.")
  ut <- upper.tri(m)
  data.frame(i = rownames(m)[row(m)[ut]],
             j = rownames(m)[col(m)[ut]],
             cor=t(m)[ut],
             p=m[ut])
}
```

## Get sample points
Sample points that are ag in 2008.
forest, agriculture, urban, water, desert, wetlands, and bare soil
Based on looking at rasters, I assume these are the value/land cover class combinations:  
* 0: no data  
* 1: ag
* 2: forest
* 3: bare soil  
* 4: urban  
* 5: wetland  
* 6: desert (BOL only)  
* 7: water  

### Brazil
```{r}
### Open Brazil 2008 raster
bra_2008 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_BRA_dry_2008.tif")

# hist(bra_2008,
#      main = "Distribution of land cover classes",
#      xlab = "Land cover class", ylab = "Frequency",
#      col = "springgreen")

### Reclassification matrix (want forests + NA only)
reclass_df <- c(-1, 1.1, NA, ## change NoData, ag to NA
                1.9, 2.1, 1, ## forest = 1
                2.9, 10, NA) ## all other classes = NA
reclass_m <- matrix(reclass_df,
                ncol = 3,
                byrow = TRUE)

### Reclassify raster
bra_2008_recl <- reclassify(bra_2008, reclass_m)
hist(bra_2008_recl,
     main = "Distribution of land cover classes",
     xlab = "Land cover class", ylab = "Frequency",
     col = "springgreen")

### Get sample of points that are forest (1) in 2008
### Tried with sample of 1000 pts but didn't get enough points with a transition (59 turned to ag, 8 to bare soil, 1 to wetland)
forest_pts <- fastRandomPoints(r = bra_2008_recl,
                               n = 100000)

### Make it a df
forest_pts <- as_data_frame(forest_pts) %>%
  rownames_to_column(., "sample_pt")

### Convert to sf
forest_pts_sf <- st_as_sf(x = forest_pts,
                          coords = c("x", "y"),
                          crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

### Save sf df
st_write(forest_pts_sf, "bra_pts_for_regression.shp")
```

#### See LUC in 2018 for pts
```{r}
### Convert to sp
forest_pts_sp <- as(forest_pts_sf, "Spatial")

### Open 2018 raster
bra_2018 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_BRA_dry_2018.tif")

### Extract raster values to sample pts
luc_2018 <- raster::extract(bra_2018, forest_pts_sp, df = TRUE)

### Histogram and summary
hist(luc_2018$classi_BRA_dry_2018)
luc_2018_summ <- luc_2018 %>% 
  group_by(classi_BRA_dry_2018) %>% 
  summarise(pts_per_class = n())
```

### Bolivia
```{r}
### Open Bolivia 2008 raster
bol_2008 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_BOL_dry_2008.tif")

hist(bol_2008,
     main = "Distribution of land cover classes",
     xlab = "Land cover class", ylab = "Frequency",
     col = "springgreen")

### Reclassification matrix (want forests + NA only)
reclass_df <- c(-1, 1.1, NA, ## change NoData, ag to NA
                1.9, 2.1, 1, ## forest = 1
                2.9, 10, NA) ## all other classes = NA
reclass_m <- matrix(reclass_df,
                ncol = 3,
                byrow = TRUE)

### Reclassify raster
bol_2008_recl <- reclassify(bol_2008, reclass_m)
hist(bol_2008_recl,
     main = "Distribution of land cover classes",
     xlab = "Land cover class", ylab = "Frequency",
     col = "springgreen")

### Get sample of points that are forest (1) in 2008
forest_pts_bol <- fastRandomPoints(r = bol_2008_recl,
                                   n = 10000)

### Make it a df
forest_pts_bol <- as_data_frame(forest_pts_bol) %>%
  rownames_to_column(., "sample_pt")

### Convert to sf
forest_pts_bol_sf <- st_as_sf(x = forest_pts_bol,
                          coords = c("x", "y"),
                          crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

### Save sf df
st_write(forest_pts_bol_sf, "bol_pts_for_regression.shp")
```

#### See LUC in 2018 for pts
```{r}
### Convert to sp
forest_pts_bol_sp <- as(forest_pts_bol_sf, "Spatial")

### Open 2018 raster
bol_2018 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_BOL_dry_2018.tif")

### Extract raster values to sample pts
luc_2018_bol <- raster::extract(bol_2018, 
                                forest_pts_bol_sp, 
                                df = TRUE)

### Histogram and summary
hist(luc_2018_bol$classi_BOL_dry_2018)
luc_2018_bol_summ <- luc_2018_bol %>% 
  group_by(classi_BOL_dry_2018) %>% 
  summarise(pts_per_class = n())
```

### Peru
```{r}
### Open Peru 2008 raster
per_2008 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_PER_dry_2008.tif")

hist(per_2008,
     main = "Distribution of land cover classes",
     xlab = "Land cover class", ylab = "Frequency",
     col = "springgreen")

### Reclassification matrix (want forests + NA only)
reclass_df <- c(-1, 1.1, NA, ## change NoData, ag to NA
                1.9, 2.1, 1, ## forest = 1
                2.9, 10, NA) ## all other classes = NA
reclass_m <- matrix(reclass_df,
                ncol = 3,
                byrow = TRUE)

### Reclassify raster
per_2008_recl <- reclassify(per_2008, reclass_m)
hist(per_2008_recl,
     main = "Distribution of land cover classes",
     xlab = "Land cover class", ylab = "Frequency",
     col = "springgreen")

### Get sample of points that are forest (1) in 2008
### 10,000 pts is not enough for Peru-- only had 27 points that transitioned
## 30,000 pts --> 92 transitioned
forest_pts_per <- fastRandomPoints(r = per_2008_recl,
                                   n = 100000)

### Make it a df
forest_pts_per <- as_data_frame(forest_pts_per) %>%
  rownames_to_column(., "sample_pt")

### Convert to sf
forest_pts_per_sf <- st_as_sf(x = forest_pts_per,
                          coords = c("x", "y"),
                          crs = "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")

### Save sf df
st_write(forest_pts_per_sf, "per_pts_for_regression.shp")
```

#### See LUC in 2018 for pts
```{r}
### Convert to sp
forest_pts_per_sp <- as(forest_pts_per_sf, "Spatial")

### Open 2018 raster
per_2018 <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_PER_dry_2018.tif")

### Extract raster values to sample pts
luc_2018_per <- raster::extract(per_2018, 
                                forest_pts_per_sp, 
                                df = TRUE)

### Summary
luc_2018_per_summ <- luc_2018_per %>% 
  group_by(classi_PER_dry_2018) %>% 
  summarise(pts_per_class = n())

# ### Double check that all pts are forest in 2008
# lc_2008 <- raster::extract(per_2008,
#                            forest_pts_per_sp, 
#                            df = TRUE)
# lc_2008_per_summ <- lc_2008 %>% 
#   group_by(classi_PER_dry_2008) %>% 
#   summarise(pts_per_class = n())
```

## Grid sample
### Brazil
```{r}
### Brazil case study shape file
jaman_shp <- st_read("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/case_study_shp/JamanBuffer/JamanBuffer_reproj.shp") %>%

  ### Convert to metric
  st_transform(crs = "+proj=utm +zone=12 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")

### Make sampling grid, point every 1 km
# samples <- map(jaman_shp$NAME_1, function(x){
# 
#   ### For each state
#   state_poly <- west %>% filter(NAME_1 == x)
jaman_samples <- jaman_shp %>%
  
  ### Make samples
  st_make_grid(cellsize = c(1000, 1000), 
               what = "centers") %>%
  
  ### Convert to sf
  st_sf()  %>%
  
  ### Add identifiers
  mutate(lon = st_coordinates(.)[,1],
         lat = st_coordinates(.)[,2])

### Back to 102033
jaman_samples <- jaman_samples %>%
  st_transform(crs = 102033)
jaman_shp <- jaman_shp %>%
  st_transform(crs = 102033)

# ### Write out to check
# st_write(jaman_samples, "bra_pts_grid.shp")

### Remove points that fall outside of study area
jaman_pts <- st_intersection(jaman_samples, jaman_shp) 

### Convert pts to sp
jaman_pts_sp <- as(jaman_pts, "Spatial")

### Extract 2008 land cover type to pts
bra_lc_2008 <- extract(bra_2008, 
                       jaman_pts_sp,
                       df = TRUE)

### See how many are forested in 2008
bra_lc_2008_summ <- bra_lc_2008 %>%
  group_by(classi_bra_dry_2008_102033) %>%
  summarise(n_pts = n())
```

This yields 75,600 pts for regression

## Simple Models
### Brazil
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Open Brazil sample pts, reproject to 102033
bra_pts <- st_read("bra_pts_for_regression.shp") %>%
  st_transform(., crs = 102033)

### Open Brazil rasterbrick
bra_layers <- brick("D:/dinamica/brazil_simple/data/brazil_static_vars.tif")

### Convert pts to sp
bra_pts_sp <- as(bra_pts, "Spatial")

### Extract values to pts
bra_dat <- extract(bra_layers, 
                   bra_pts_sp,
                   df = TRUE)

### Rename columns
colnames(bra_dat) <- c("id", "aspect", "mines", 
                       "roads", "rivers", 
                       "cities", "elev", 
                       "popdens", "poverty", 
                       "ppt", "prot_status", 
                       "slope", "soil", 
                       'crop_suit')

### Open 2018 land cover map
bra_2018_lc <- raster("D:/dinamica/brazil_simple/data/classi_bra_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(bra_2018_lc, 
                    bra_pts_sp,
                    df = TRUE)
colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
bra_dat <- merge(bra_dat, pts_2018, by = "id")

### Make column for transition/none
bra_dat <- bra_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_status", "lc_2018", "trans_rc")
bra_dat <- bra_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bra <- flattenSquareMatrix(cor.prob(bra_dat[, c(2:10, 12:14)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bra <- subset(cor_table_bra, 
                        abs(cor) > 0.66 & p <= 0.05)

### Population density and poverty rate are highly correlated (correlation coefficient = 0.93)

### Make updated dataset
bra_dat_red <- bra_dat %>%
  dplyr::select(-poverty)

### Drop incomplete rows
bra_dat_comp <- bra_dat_red[complete.cases(bra_dat_red), ]

### Drop rows where prot_status = 0 (??)
bra_dat_comp <- bra_dat_comp %>%
  filter(., !prot_status == "0")

### Summarize transitions
bra_dat_summ <- bra_dat_comp %>%
  group_by(lc_2018) %>%
  summarise(n_pts_2018 = n())
```

#### Regression
```{r}
### Run regression
fit_bra <- glm(trans_rc ~ aspect + slope + elev +
                 roads + rivers + cities + mines +
                 ppt + soil + crop_suit +
                 popdens + prot_status,
               data = bra_dat_comp,
               family = binomial(link = "logit"))

### Write out coefficients
fit_bra_summ <- summary(fit_bra)
fit_bra_coeff <- as.data.frame(fit_bra_summ$coefficients)
write.csv(fit_bra_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_bra_simple_summary.csv")
```

### Bolivia
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Open Bolivia sample pts, reproject to 102033
bol_pts <- st_read("bol_pts_for_regression.shp") %>%
  st_transform(., crs = 102033)

### Open Bolivia rasterbrick
bol_layers <- brick("D:/dinamica/bolivia_simple/data/bolivia_static_vars.tif")

### Convert pts to sp
bol_pts_sp <- as(bol_pts, "Spatial")

### Extract values to pts
bol_dat <- extract(bol_layers, 
                   bol_pts_sp,
                   df = TRUE)

### Rename columns
colnames(bol_dat) <- c("id", "aspect", "mines", 
                       "roads", "rivers", 
                       "cities", "elev", 
                       "popdens", "poverty", 
                       "ppt", "prot_status", 
                       "slope", "soil", 
                       'crop_suit')

### Open 2018 land cover map
bol_2018_lc <- raster("D:/dinamica/bolivia_simple/data/classi_bol_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(bol_2018_lc, 
                    bol_pts_sp,
                    df = TRUE)
colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
bol_dat <- merge(bol_dat, pts_2018, by = "id")

### Make column for transition/none
bol_dat <- bol_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_status", "lc_2018", "trans_rc")
bol_dat <- bol_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat[, c(2:10, 12:14)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Distance to roads and distance to cities highly correlated (coeff = 0.7297491)
### Poverty and soil moisture are highly correlated (coeff = 0.7979029)

### Drop poverty (because also dropped that for DINAMICA), drop distance to cities

### Make updated dataset
bol_dat_red <- bol_dat %>%
  dplyr::select(-poverty, -cities)

### Drop incomplete rows
bol_dat_comp <- bol_dat_red[complete.cases(bol_dat_red), ]

### Drop rows where prot_status = 0 (??)
bol_dat_comp <- bol_dat_comp %>%
  filter(., !prot_status == "0")
```

#### Regression
```{r}
### Run regression
fit_bol <- glm(trans_rc ~ aspect + slope + elev +
                 roads + rivers + mines +
                 ppt + soil + crop_suit +
                 popdens + prot_status,
               data = bol_dat_comp,
               family = binomial(link = "logit"))

### Write out coefficients
fit_bol_summ <- summary(fit_bol)
fit_bol_coeff <- as.data.frame(fit_bol_summ$coefficients)
write.csv(fit_bol_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_bol_simple_summary.csv")
```

### Peru
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Open Peru sample pts, reproject to 102033
per_pts <- st_read("per_pts_for_regression.shp") %>%
  st_transform(., crs = 102033)

### Open Peru rasterbrick
per_layers <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/peru_dinamica/data/per_static_vars.tif")

### Convert pts to sp
per_pts_sp <- as(per_pts, "Spatial")

### Extract values to pts
per_dat <- extract(per_layers, 
                   per_pts_sp,
                   df = TRUE)

### Rename columns
colnames(per_dat) <- c("id", "aspect", "cities", "cropsuit",
                       "elev", "mines", "prot_stat",
                       "popdens", "pov", "precip",
                       "rivers", "roads", "slope",
                       "soil_moisture")

### Open 2018 land cover map
per_2018_lc <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_per_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(per_2018_lc, 
                    per_pts_sp,
                    df = TRUE)

colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
per_dat <- merge(per_dat, pts_2018, by = "id")

### Make column for transition/none
per_dat <- per_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_stat", "lc_2018", "trans_rc")
per_dat <- per_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_per <- flattenSquareMatrix(cor.prob(per_dat[, c(2:6, 8:14)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_per <- subset(cor_table_per, 
                        abs(cor) > 0.66 & p <= 0.05)

### Distance to cities and distance to mines (0.8214095)
### Pop density and poverty rate (0.9452610)
### Distance to rivers and roads (1.0000000)
### Elevation and slope (0.7843344)
### Elevation and soil moisture (0.7201558)
### Slope and soil moisture (0.7187970)

### Drop slope, distance to roads, distance to mines, poverty rate, soil moisture

### Make updated dataset
per_dat_red <- per_dat %>%
  dplyr::select(-pov, -roads, -mines, -slope, -soil_moisture)

### Drop incomplete rows
per_dat_comp <- per_dat_red[complete.cases(per_dat_red), ]

### Drop rows where prot_status = 0 (??)
per_dat_comp <- per_dat_comp %>%
  filter(., !prot_stat == "0")
```

#### Regression
```{r}
### Run regression
fit_per <- glm(trans_rc ~ aspect + elev +
                 cities + rivers +
                 precip + cropsuit +
                 popdens + prot_stat,
               data = per_dat_comp,
               family = binomial(link = "logit"))

### Write out coefficients
fit_per_summ <- summary(fit_per)
fit_per_coeff <- as.data.frame(fit_per_summ$coefficients)
write.csv(fit_per_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_per_simple_summary.csv")
```


## Grid Points, Simple Models
### Brazil
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Convert pts to sp
jaman_pts_sp <- as(jaman_pts, "Spatial")

### Extract 2008 land cover type to pts
bra_lc_2008 <- extract(bra_2008, 
                       jaman_pts_sp,
                       df = TRUE)
colnames(bra_lc_2008) <- c("id", "lc_2008")

### Open Brazil rasterbrick
bra_layers <- brick("D:/dinamica/brazil_simple/data/brazil_static_vars.tif")

### Extract values to pts
bra_dat <- extract(bra_layers, 
                   jaman_pts_sp,
                   df = TRUE)

### Rename columns
colnames(bra_dat) <- c("id", "aspect", "mines", 
                       "roads", "rivers", 
                       "cities", "elev", 
                       "popdens", "poverty", 
                       "ppt", "prot_status", 
                       "slope", "soil", 
                       'crop_suit')

### Combine
bra_dat <- merge(bra_dat, bra_lc_2008, by = "id")

### Open 2018 land cover map
bra_2018_lc <- raster("D:/dinamica/brazil_simple/data/classi_bra_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(bra_2018_lc, 
                    jaman_pts_sp,
                    df = TRUE)
colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
bra_dat <- merge(bra_dat, pts_2018, by = "id")

### Remove if lc_2008 =/= 2
bra_dat_keep <- bra_dat %>%
  filter(lc_2008 == 2)

### Make column for transition/none
bra_dat_keep <- bra_dat_keep %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_status", "lc_2018", "trans_rc")
bra_dat_keep <- bra_dat_keep %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bra <- flattenSquareMatrix(cor.prob(bra_dat[, c(2:10, 12:14)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bra <- subset(cor_table_bra, 
                        abs(cor) > 0.66 & p <= 0.05)

### Population density and poverty rate are highly correlated (correlation coefficient = 0.93)

### Make updated dataset
bra_dat_red <- bra_dat_keep %>%
  dplyr::select(-poverty)

### Drop incomplete rows
bra_dat_comp <- bra_dat_red[complete.cases(bra_dat_red), ]

### Drop rows where prot_status = 0 (??)
bra_dat_comp <- bra_dat_comp %>%
  filter(., !prot_status == "0")

### Summarize transitions
bra_dat_summ <- bra_dat_comp %>%
  group_by(lc_2018) %>%
  summarise(n_pts_2018 = n())
```

#### Regression
```{r}
### Run regression
fit_bra <- glm(trans_rc ~ aspect + slope + elev +
                 roads + rivers + cities + mines +
                 ppt + soil + crop_suit +
                 popdens + prot_status,
               data = bra_dat_comp,
               family = binomial(link = "logit"))

### Write out coefficients
fit_bra_summ <- summary(fit_bra)
fit_bra_coeff <- as.data.frame(fit_bra_summ$coefficients)
write.csv(fit_bra_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_bra_simple_summary.csv")
```

## Full models
Simple models + discourse analysis layers
### Brazil
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Open Brazil sample pts, reproject to 102033
bra_pts <- st_read("bra_pts_for_regression.shp") %>%
  st_transform(., crs = 102033)

### Open braivia rasterbrick, all layers
bra_layers_all <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/brazil/discourse_analysis_final_layers/brazil_all_layers.tif")

### Convert pts to sp
bra_pts_sp <- as(bra_pts, "Spatial")

### Extract values to pts
bra_dat <- extract(bra_layers_all, 
                   bra_pts_sp,
                   df = TRUE)

### Rename columns
colnames(bra_dat) <- c("id", "aspect", "mines", 
                       "roads", "rivers", 
                       "cities", "elev", 
                       "popdens", "poverty", 
                       "ppt", "prot_status", 
                       "slope", "soil", 
                       "crop_suit", "field_research", 
                       "paddd",
                       "non_all_land",
                       "dist_ill_mines",
                       "dist_ag",
                       "dist_fires",
                       "fire_dens",
                       "dist_proposed_rr",
                       "dist_proposed_dams",
                       "agreform_sett",
                       "cattle")

### Open 2018 land cover map
bra_2018_lc <- raster("D:/dinamica/brazil_simple/data/classi_bra_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(bra_2018_lc, 
                    bra_pts_sp,
                    df = TRUE)
colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
bra_dat <- merge(bra_dat, pts_2018, by = "id")

### Make column for transition/none
bra_dat <- bra_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_status", "paddd",
               "agreform_sett",
               "lc_2018", "trans_rc")
bra_dat <- bra_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bra <- flattenSquareMatrix(cor.prob(bra_dat[, c(2:10, 12:15, 17:23, 25)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bra <- subset(cor_table_bra, 
                        abs(cor) > 0.66 & p <= 0.05)

### Highly correlated variables
### Pop density and poverty (coeff = 0.9276640)
### Pop density and % non-allocated land (coeff = 0.9983248)
### Poverty and % non-allocated land (coeff = 0.9277938)
### Precip and dist to illegal mines (coeff = -0.8128244)
### Field research and proposed RR (coeff = 0.7268175)
### Cities and proposed dams (coeff = 0.8935432)
### Precip and proposed dams (coeff = -0.7179452)
### Illegal mines and proposed dams (coeff = 0.7017285)
### Population density and cattle (coeff = -0.9614797)
### Poverty and cattle (coeff = -0.9942979)
### Non-alloc land and cattle (coeff = -0.9619244)

### Drop: cattle, dist_proposed_dams, poverty, ppt, dist_proposed_rr, non_all_land

### Make updated dataset
bra_dat_red <- bra_dat %>%
  dplyr::select(-poverty, -cattle, -dist_proposed_dams,
                -ppt, -dist_proposed_rr, -non_all_land)

### Drop incomplete rows
bra_dat_comp <- bra_dat_red[complete.cases(bra_dat_red), ]

### Drop rows where prot_status = 0 (??)
bra_dat_comp <- bra_dat_comp %>%
  filter(., !prot_status == "0")
```

#### Regression
```{r}
### Run regression
fit_bra_all <- glm(trans_rc ~ aspect + slope + elev +
                     roads + rivers + mines +
                     cities + popdens +
                   soil + crop_suit +
                     prot_status +
                     field_research + paddd +
                     dist_ill_mines + dist_ag +
                     dist_fires + fire_dens +
                     agreform_sett,
                   data = bra_dat_comp,
                   family = binomial(link = "logit"))

### Write out coefficients
fit_bra_summ <- summary(fit_bra_all)
fit_bra_coeff <- as.data.frame(fit_bra_summ$coefficients)
write.csv(fit_bra_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_bra_full_summary.csv")
```

### Bolivia
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
### Open Bolivia sample pts, reproject to 102033
bol_pts <- st_read("bol_pts_for_regression.shp") %>%
  st_transform(., crs = 102033)

### Open Bolivia rasterbrick, all layers
bol_layers_all <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/bolivia/discourse_analysis_final_layers/bolivia_all_vars.tif")

### Convert pts to sp
bol_pts_sp <- as(bol_pts, "Spatial")

### Extract values to pts
bol_dat <- extract(bol_layers_all, 
                   bol_pts_sp,
                   df = TRUE)

### Rename columns
colnames(bol_dat) <- c("id", "aspect", "mines", 
                       "roads", "rivers", 
                       "cities", "elev", 
                       "popdens", "poverty", 
                       "ppt", "prot_status", 
                       "slope", "soil", 
                       "crop_suit", "dist_ag", 
                       "dist_fire", "fire_dens",
                       "ill_mine", "field_res",
                       "tourism", "pes")

### Open 2018 land cover map
bol_2018_lc <- raster("D:/dinamica/bolivia_simple/data/classi_bol_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018 <- extract(bol_2018_lc, 
                    bol_pts_sp,
                    df = TRUE)
colnames(pts_2018) <- c("id", "lc_2018")

### Combine dfs
bol_dat <- merge(bol_dat, pts_2018, by = "id")

### Make column for transition/none
bol_dat <- bol_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_status", "pes",
               "lc_2018", "trans_rc")
bol_dat <- bol_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat[, c(2:10, 12:20)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Highly correlated variables
### Distance to roads and distance to cities (coeff = 0.7297491)
### Poverty and soil moisture (coeff = 0.7979029)
### Poverty and distance to illegal mines (coeff = -0.7781607)
### Soil moisture and distance to illegal mines (coeff = -0.8504490)

### Drop poverty, distance to cities, distance to illegal mines

### Make updated dataset
bol_dat_red <- bol_dat %>%
  dplyr::select(-poverty, -cities, -ill_mine)

### Drop incomplete rows
bol_dat_comp <- bol_dat_red[complete.cases(bol_dat_red), ]

### Drop rows where prot_status = 0 (??)
bol_dat_comp <- bol_dat_comp %>%
  filter(., !prot_status == "0")
```

#### Regression
```{r}
### Run regression
fit_bol_all <- glm(trans_rc ~ aspect + slope + elev +
                     roads + rivers + mines +
                     ppt + soil + crop_suit +
                     popdens + prot_status +
                     dist_ag + dist_fire +
                     fire_dens + field_res +
                     tourism + pes,
                   data = bol_dat_comp,
                   family = binomial(link = "logit"))

### Write out coefficients
fit_bol_summ <- summary(fit_bol_all)
fit_bol_coeff <- as.data.frame(fit_bol_summ$coefficients)
write.csv(fit_bol_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_bol_full_summary.csv")
```

### Peru
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
# ### Open Peru sample pts, reproject to 102033
# per_pts <- st_read("per_pts_for_regression.shp") %>%
#   st_transform(., crs = 102033)

### Open Peru rasterbrick, all layers
per_layers_all <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/peru_dinamica/data/peru_all_layers.tif")

# ### Convert pts to sp
# per_pts_sp <- as(per_pts, "Spatial")

### Extract values to pts
per_dat_all <- extract(per_layers_all, 
                       per_pts_sp,
                       df = TRUE)

### Rename columns
colnames(per_dat_all) <- c("id", "aspect", 
                           "cities", "cropsuit",
                           "elev", "mines",
                           "prot_stat", "popdens",
                           "pov", "precip",
                           "rivers", "roads",
                           "slope", "soil_moist",
                           "ag_dist", "control_stations",
                           "dist_communities", "dist_fire",
                           "dist_forest", "dist_ill_mines",
                           "dist_mine_concess", 
                           "nonforest_concess",
                           "paddd", "nut_prod",
                           "prot_forest", "reforestation",
                           "tourism")

### Switch NAs to 0s in nonforest_concess, paddd, nut_prod, prot_forest, reforestation
per_dat_all$nonforest_concess[is.na(per_dat_all$nonforest_concess)] <- 0
per_dat_all$paddd[is.na(per_dat_all$paddd)] <- 0
per_dat_all$nut_prod[is.na(per_dat_all$nut_prod)] <- 0
per_dat_all$prot_forest[is.na(per_dat_all$prot_forest)] <- 0
per_dat_all$reforestation[is.na(per_dat_all$reforestation)] <- 0

### Open 2018 land cover map
per_2018_lc <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/remote_sensing/classi_per_dry_2018_102033.tif")

### Extract 2018 land cover class to points
pts_2018_all <- extract(per_2018_lc, 
                        per_pts_sp,
                        df = TRUE)
colnames(pts_2018_all) <- c("id", "lc_2018")

### Combine dfs
per_dat_all <- merge(per_dat_all, 
                     pts_2018_all, by = "id")

### Make column for transition/none
per_dat_all <- per_dat_all %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("id", "prot_stat", 
               "nonforest_concess", "paddd",
               "nut_prod", "prot_forest",
               "reforestation",
               "lc_2018", "trans_rc")
per_dat_all <- per_dat_all %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_per_all <- flattenSquareMatrix(cor.prob(per_dat_all[, c(2:6, 8:21, 27)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_per_all <- subset(cor_table_per_all, 
                            abs(cor) > 0.66 & p <= 0.05)

### Highly correlated variables
### cities and mines
### popdens and pov
### rivers and roads
### elev and slope
### elev and soil moisture
### slope and soil_moist 
### pov and control_stations 
### elev and dist_communities 
### pov and dist_communities 
### control_stations and dist_communities 
### cities and dist_ill_mines 
### mines and dist_ill_mines 
### cities and dist_mine_concess 
### mines and dist_mine_concess 
### dist_ill_mines and dist_mine_concess

### Drop dist_mine_concess, slope, soil_moist, dist_communities, dist_ill_mines, pov, mines, roads  

### Make updated dataset
per_dat_all_red <- per_dat_all %>%
  dplyr::select(-dist_mine_concess, -slope, 
                -soil_moist, -dist_communities,
                -dist_ill_mines, -pov, 
                -mines, -roads)

### Drop incomplete rows
per_dat_all_comp <- per_dat_all_red[complete.cases(per_dat_all_red), ]

### Drop rows where prot_status = 0 (??)
per_dat_all_comp <- per_dat_all_comp %>%
  filter(., !prot_stat == "0")
```

#### Regression
```{r}
### Run regression
fit_per_all <- glm(trans_rc ~ aspect + elev +
                     rivers + cities +
                     precip + cropsuit +
                     popdens + prot_stat +
                     ag_dist + control_stations +
                     dist_fire + dist_forest +
                     nonforest_concess + paddd +
                     nut_prod + prot_forest +
                     reforestation + tourism,
                   data = per_dat_all_comp,
                   family = binomial(link = "logit"))

### Write out coefficients
fit_per_summ <- summary(fit_per_all)
fit_per_coeff <- as.data.frame(fit_per_summ$coefficients)
write.csv(fit_per_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/visuals_feb/fit_per_full_summary.csv")
```

## AAG PRESENTATION
Show different models for Bolivia

### Sample on grid
Adapt code from western fires
```{r}
### Open buffer polygon
bol_buff <- st_read("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/case_study_shp/AmbCar/ambcar_buffer_updated.shp")

### Make sampling grid, point every 1 km
bol_samples <- bol_buff %>%
  
  ### Make samples
  st_make_grid(cellsize = c(500, 500),
               what = "centers") %>%
  
  ### Convert to sf
  st_sf() %>%
  
  ### Add identifiers
  mutate(lon = st_coordinates(.)[, 1],
         lat = st_coordinates(.)[, 2])

### Add UID
bol_samples$uid <- 1:nrow(bol_samples)

### Extract land cover type to sample points
bol_samples_2008 <- raster::extract(bol_2008, 
                                    bol_samples, 
                                    df = TRUE)

### See how many were forest in 2008
b_2008_summ <- bol_samples_2008 %>%
  group_by(classi_BOL_dry_2008) %>%
  summarise(n_per_class = n())
### 19815 forested points in 2008

### Add uid back in
bol_samples_2008$uid <- bol_samples$uid

### Merge bol_samples_2008 with bol_samples
bol_samples <- merge(bol_samples, 
                     bol_samples_2008,
                     by = "uid")

### Subset to forested points
bol_forest_samp <- bol_samples %>%
  subset(classi_BOL_dry_2008 == "2")

### Extract 2018 land cover class
luc_bol <- raster::extract(bol_2018, 
                           bol_forest_samp, 
                           df = TRUE)

### Add UID and merge with sf
luc_bol$uid <- bol_forest_samp$uid
luc_bol <- merge(luc_bol, 
                 bol_forest_samp,
                 by = "uid")

### Summarize transitions
luc_bol_summ <- luc_bol %>%
  group_by(classi_BOL_dry_2018) %>%
  summarise(n_transitions = n())

### Drop points that transitioned to other land uses
luc_bol_fa <- luc_bol %>%
  subset(classi_BOL_dry_2018 < 3)

### Make sf
st_geometry(luc_bol_fa) <- luc_bol_fa$geometry

### Rename cols
luc_bol_fa <- luc_bol_fa %>%
  dplyr::select(uid, 
                lc_2008 = classi_BOL_dry_2008,
                lc_2018 = classi_BOL_dry_2018,
                lon, lat, geometry)

### Save sf df
st_write(luc_bol_fa, "bol_gridpts_for_regression.shp")
```

### UIDs of points with complete data
```{r}
### Open Bol points
luc_bol_fa <- st_read("bol_gridpts_for_regression.shp")

### Open Bolivia rasterbrick, all layers
bol_layers_all <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/bolivia/discourse_analysis_final_layers/bolivia_all_vars.tif")

### Extract values to pts
bol_dat_all <- extract(bol_layers_all, 
                       luc_bol_fa,
                       df = TRUE)

### Rename columns
colnames(bol_dat_all) <- c("id", "aspect", "mines", 
                           "roads", "rivers", 
                           "cities", "elev", 
                           "popdens", "poverty", 
                           "ppt", "prot_status", 
                           "slope", "soil", 
                           "crop_suit", "dist_ag", 
                           "dist_fire", "fire_dens",
                           "ill_mine", "field_res",
                           "tourism", "pes")

### Give it a uid
bol_dat_all$uid <- luc_bol_fa$uid

### Merge with sf
bol_dat_all <- merge(bol_dat_all, luc_bol_fa,
                     by = "uid")

### Open cow raster (head of cattle per area)
cattle <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/bolivia/discourse_analysis_final_layers/bol_cows.tif")

### Extract cattle
bol_cattle <- extract(cattle, 
                      luc_bol_fa,
                      df = TRUE)

### Give it a uid
bol_cattle$uid <- luc_bol_fa$uid

### Merge with rest of data
bol_dat_all <- merge(bol_dat_all, 
                     bol_cattle,
                     by = "uid")

### Drop geometry
bol_dat_all_simp <- bol_dat_all
bol_dat_all_simp$geometry <- NULL

### Drop incomplete rows
bol_dat_all_simp <- bol_dat_all_simp[complete.cases(bol_dat_all_simp), ]

### Drop rows where prot_status = 0 (??)
bol_dat_all_simp <- bol_dat_all_simp %>%
  filter(., !prot_status == "0")

### Get uids
uid_comp <- bol_dat_all_simp$uid

### Add geom back to visualize
st_geometry(bol_dat_all) <- bol_dat_all$geometry
bol_dat_all <- bol_dat_all %>%
  filter(uid %in% uid_comp)

### Drop geom for regressions
bol_dat <- bol_dat_all
st_geometry(bol_dat) <- NULL

### Make column for transition/none
bol_dat <- bol_dat %>%
  mutate(transition = ifelse(lc_2018 == "2",
                             "no_change",
                             "change"),
         trans_rc = ifelse(transition == "no_change",
                           "0", "1"))

### Make columns factor
fact_cols <- c("uid", "prot_status", "pes",
               "lc_2018", "trans_rc")
bol_dat <- bol_dat %>%
  mutate_each_(funs(factor(.)), fact_cols)
```

### Model 1
Standard LUC variables only
#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
# ### Open Bol points
# luc_bol_fa <- st_read("bol_gridpts_for_regression.shp")
# 
# ### Open Bolivia rasterbrick
# bol_layers <- brick("D:/dinamica/bolivia_simple/data/bolivia_static_vars.tif")
# 
# ### Convert pts to sp
# bol_pts_sp <- as(luc_bol_fa, "Spatial")
# 
# ### Extract values to pts
# bol_dat <- extract(bol_layers, 
#                    bol_pts_sp,
#                    df = TRUE)
# 
# ### Rename columns
# colnames(bol_dat) <- c("id", "aspect", "mines", 
#                        "roads", "rivers", 
#                        "cities", "elev", 
#                        "popdens", "poverty", 
#                        "ppt", "prot_status", 
#                        "slope", "soil", 
#                        'crop_suit')
# 
# ### Give it a uid
# bol_dat$uid <- bol_pts_sp$uid
# 
# ### Merge with sf
# bol_dat <- merge(bol_dat, luc_bol_fa,
#                  by = "uid")
# 
# ### Make column for transition/none
# bol_dat <- bol_dat %>%
#   mutate(transition = ifelse(lc_2018 == "2",
#                              "no_change",
#                              "change"),
#          trans_rc = ifelse(transition == "no_change",
#                            "0", "1"))
# 
# ### Make columns factor
# fact_cols <- c("uid", "prot_status", "lc_2018", "trans_rc")
# bol_dat <- bol_dat %>%
#   mutate_each_(funs(factor(.)), fact_cols)
```

#### Check correlations
```{r}
### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat[, c(3:11, 13:15, 
                                                          25, 26)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Distance to roads and distance to cities highly correlated (coeff = 0.7254542)
### Roads and precipitation (0.6751290)
### Poverty and soil moisture are highly correlated (coeff = 0.7205976)
### Poverty and longitude (-0.7764958)
### Soil and longitude (-0.9706443)
### Precip and latitude (0.8522991)

### Drop soil moisture (poverty, longitude), distance to cities (distance to roads), precip (latitude, roads), longitude (poverty)

### Make updated dataset
bol_dat_red <- bol_dat %>%
  dplyr::select(-soil, -cities, -ppt, -lon)
```

#### Regression
```{r}
### Run regression
fit_bol <- glm(trans_rc ~ aspect + slope + elev +
                 roads + rivers + mines +
                 crop_suit + popdens + poverty +
                 # (1|uid) +
                 lat + prot_status,
               data = bol_dat_red,
               family = binomial(link = "logit"))

### Write out coefficients
fit_bol_summ <- summary(fit_bol)
fit_bol_coeff <- as.data.frame(fit_bol_summ$coefficients)
write.csv(fit_bol_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/analyses_aag/fit_bol_model1.csv")
```

### Model 2
Discourse analysis variables only

#### Assemble datasets
Extract values from rasterbricks to sample points
```{r}
# ### Open Bolivia rasterbrick, all layers
# bol_layers_all <- brick("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/bolivia/discourse_analysis_final_layers/bolivia_all_vars.tif")
# 
# ### Extract values to pts
# bol_dat_2 <- extract(bol_layers_all, 
#                       bol_pts_sp,
#                       df = TRUE)
# 
# ### Rename columns
# colnames(bol_dat_2) <- c("id", "aspect", "mines", 
#                        "roads", "rivers", 
#                        "cities", "elev", 
#                        "popdens", "poverty", 
#                        "ppt", "prot_status", 
#                        "slope", "soil", 
#                        "crop_suit", "dist_ag", 
#                        "dist_fire", "fire_dens",
#                        "ill_mine", "field_res",
#                        "tourism", "pes")
# 
# ### Give it a uid
# bol_dat_2$uid <- bol_pts_sp$uid
# 
# ### Merge with sf
# bol_dat_2 <- merge(bol_dat_2, luc_bol_fa,
#                  by = "uid")
# 
# ### Open cow raster (head of cattle per area)
# cattle <- raster("C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/new_dinamica_layers/bolivia/discourse_analysis_final_layers/bol_cows.tif")
# 
# ### Extract cattle
# bol_cattle <- extract(cattle, 
#                       bol_pts_sp,
#                       df = TRUE)
# 
# ### Give it a uid
# bol_cattle$uid <- bol_pts_sp$uid
# 
# ### Merge with rest of data
# bol_dat_2 <- merge(bol_dat_2, bol_cattle,
#                  by = "uid")
# 
# ### Make column for transition/none
# bol_dat_2 <- bol_dat_2 %>%
#   mutate(transition = ifelse(lc_2018 == "2",
#                              "no_change",
#                              "change"),
#          trans_rc = ifelse(transition == "no_change",
#                            "0", "1"))
# 
# ### Make columns factor
# fact_cols <- c("id", "prot_status", "pes", "lc_2008",
#                "lc_2018", "trans_rc")
# bol_dat_2 <- bol_dat_2 %>%
#   mutate_each_(funs(factor(.)), fact_cols)
# 
# ### Drop variables I don't need for model 2
# bol_dat_m2 <- bol_dat_2 %>%
#   dplyr::select(-aspect, -slope, -elev,
#                 -mines, -roads, -rivers,
#                 -cities, -popdens, -poverty,
#                 -ppt, -soil, -prot_status,
#                 -crop_suit)
```

#### Check correlations
Variables to include:
```{r}
### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat[, c(5, 16:21,
                                                          25, 26, 28)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Highly correlated variables
### Distance to illegal mines and longitude (0.9691501)
### Distance to field research and latitude (0.7347974)

### Drop lon and lat

### Make updated dataset
bol_dat_red_m2 <- bol_dat %>%
  dplyr::select(-lon, -lat)
```

#### Regression
```{r}
### Run regression
fit_bol_m2 <- glm(trans_rc ~ roads +
                    dist_ag + dist_fire +
                    fire_dens + field_res +
                    ill_mine + tourism + pes +
                    bol_cows,
                  data = bol_dat_red_m2,
                  family = binomial(link = "logit"))

### Write out coefficients
fit_bol2_summ <- summary(fit_bol_m2)
fit_bol2_coeff <- as.data.frame(fit_bol2_summ$coefficients)
write.csv(fit_bol2_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/analyses_aag/fit_bol_model2.csv")
```

### Model 3
All standard variables and discourse analysis variables

#### Check correlations
Use df bol_dat_2
```{r}
### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat[, c(3:11, 
                                                          13:21, 
                                                          25, 26, 
                                                          28)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Highly correlated variables
### Distance to roads and cities (0.7254542)
### Distance to roads and precip (0.6751290)
### Poverty and soil moisture (0.7205976)
### Poverty and distance to illegal mining (-0.8114084)
### Soil moisture and distance to illegal mining (-0.9036921)
### Elev and field research (-0.6948379)
### Precip and field research (0.7440272)
### Distance to mines and tourism (0.6684893)
### Poverty and longitude (-0.7764958)
### Soil moisture and longitude (-0.9706443)
### Distance to illegal mining and longitude (0.9691501)
### Precip and latitude (0.8522991)
### Field research and latitude (0.7347974)

### Drop distance to cities (distance to roads), precip (roads, latitude), poverty (soil moisture, illegal mining), soil moisture (illegal mining, longitude), distance to field research (elev, precip, latitude), distance to legal mines (tourism), longitude

### Make updated dataset
bol_dat_red_m3 <- bol_dat %>%
  dplyr::select(-lon, -soil, -ppt,
                -cities, -poverty,
                -field_res, -mines)
```

#### Regression
```{r}
### Run regression
fit_bol_m3 <- glm(trans_rc ~ aspect + slope + elev +
                    roads + rivers +
                    popdens + prot_status +
                    crop_suit + 
                    dist_ag + dist_fire +
                    fire_dens + ill_mine + 
                    tourism + pes +
                    lat + bol_cows,
                  data = bol_dat_red_m3,
                  family = binomial(link = "logit"))

### Write out coefficients
fit_bol3_summ <- summary(fit_bol_m3)
fit_bol3_coeff <- as.data.frame(fit_bol3_summ$coefficients)
write.csv(fit_bol3_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/analyses_aag/fit_bol_model3.csv")
```

### Model 4
Significant LUC variables + key DA variables:
* crop suitability, poverty rate, latitude, protection status, slope, aspect, elevation, distance to roads, rivers, mines  
* distance to northern and southern cities, fire perimeters, fire density, distance to roads, tourism, PES, cattle, land tenure


### Assemble data and check for correlations
```{r}
### Select variables for this model
bol_dat_4 <- bol_dat %>%
  dplyr::select(uid, crop_suit, poverty, prot_status, slope, aspect,
                elev, roads, mines, rivers, lat,
                dist_fire, fire_dens, tourism, pes, bol_cows,
                trans_rc)

### Make corr table
cor_table_bol <- flattenSquareMatrix(cor.prob(bol_dat_4[, c(2, 3, 5:14, 16)]))

### Look at vars with abs(cor.prob) > 0.66 and pvalue < 0.05
cor_table_bol <- subset(cor_table_bol, 
                        abs(cor) > 0.66 & p <= 0.05)

### Distance to legla mines correlated with distance to tourist sites (0.6684893)
bol_dat_4 <- bol_dat_4 %>%
  dplyr::select(-mines)
```

#### Regression
```{r}
### Run regression
fit_bol_m4 <- glm(trans_rc ~ aspect + slope + elev +
                    crop_suit + poverty +
                    prot_status + roads + 
                    rivers + lat +
                    dist_fire +
                    fire_dens + 
                    tourism + pes +
                    bol_cows,
                  data = bol_dat_4,
                  family = binomial(link = "logit"))

### Write out coefficients
fit_bol4_summ <- summary(fit_bol_m4)
fit_bol4_coeff <- as.data.frame(fit_bol4_summ$coefficients)
write.csv(fit_bol4_coeff, 
          file = "C:/Users/Katherine Siegel/Documents/SESYNC/dinamica/analyses_aag/fit_bol_model4.csv")
```

### Compare model performance
```{r}
### AIC
AIC(fit_bol, fit_bol_m2,
    fit_bol_m3, fit_bol_m4)

### Likelihood ratio test
lrtest(fit_bol, fit_bol_m3)
```

